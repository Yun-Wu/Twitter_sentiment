\section{Related Work}
\label{sec:related}

Most of previous work on sentiment analysis is based on bag-of-word model. Alec Go provided a method to use n-gram as features to analyze sentiment of Twitter \cite{Go:2009}. A. Agarwal introduced POS-specific prior polarity features and tree kernel \cite{Agarwal:2011}. S. Mohammad  combined several different features extracted from each Tweet \cite{Mohammad:2013}. None the above work take the structure of sentence into account. 

As we mentioned before, RNTN model has been tested over movie reviews and significantly outperform the bag-of-word models\cite{Socher:2013}. However, it has not been tested on twitter message yet. In our project, we apply RNTN model over Twitter corpus and compare its performance with SVM model. 


%Tokenization (splitting a string into its desired constituent parts) is fundamental to all NLP tasks. The Treebank-style is the one used by the Penn Treebank and many other important large-scale corpora for NLP. However, it has some essential drawbacks when it comes to sentiment classification. Among them, one major problem is that almost all tokens that involve punctuation are split apart â€” URLs, Twitter mark-up, emoticons, etc. Thus, emoticons are collapsed with their component parts and thus important sentimental information is lost. Therefore, we design specialized pattern for twitter tokens, such as usernames, hashtags, emoticons, etc to protect subjective expressions as much as possible. 

%However, such process is far from enough. Twitter data is different from other written English because users do not necessarily follow any formal regulations. Misspelling and slangs are quite common. \cite{Owoputi:2013} built hierarchical word clusters via Brown clustering. The algorithm partitions words into a base set of 1,000 clusters, and induces a hierarchy among those 1,000 clusters with a series of greedy agglomerative merges that heuristically optimize the likelihood of a hidden Markov model with a one-class-per-lexical-type constraint. It cannot help us because it will collapses sentiment distinctions, by collecting autonyms into the same word clusters. Fortunately, despite the variaty of online words, the transformation actually follows limited rules. With carefully designed patterns and a slang dictionary, we are able to build a corpus ready for usage of SVM and RNTN models. 

